[[/img/picture_large978-4-8144-0020-1.jpeg]]

このサイトは書籍『[[https://www.oreilly.co.jp/books/9784814400201/][SQLではじめるデータ分析]]』のサポートサイトです。

本書は「[[https://www.oreilly.com/library/view/sql-for-data/9781492088776/][SQL for Data Analysis]]」の翻訳です。

本書に掲載されているSQLは、PostgreSQLで動作するように書かれています。ここではDockerを使用し、PostgreSQLの動作環境の構築および、データの投入方法の例を紹介します。なおローカルのDocker環境は整備済みであることが前提です。

* 1. サンプルコードとデータの取得

原著者は、書籍で使ったデータとSQLを[[https://github.com/cathytanimura/sql_book][GitHub]]上で公開しています。まず、それらを取得するために、git cloneします。

#+caption: サンプルコードとデータを取得する
#+begin_src bash
git clone https://github.com/cathytanimura/sql_book.git
#+end_src


* 2. PostgreSQLコンテナの起動と接続

dockerコマンドを使用しDocker Hubからイメージを取得します。ここではサイズの小さいalpineベースのイメージを使用することにしました。

#+caption: PostgreSQLのDockerイメージを取得する
#+begin_src bash
docker pull postgres:15.0-alpine3.16
#+end_src

#+caption: PostgreSQLのDockerコンテナを起動する
#+begin_src bash
docker run -d --rm \
  --publish=127.0.0.1:5432:5432 \
  --env=POSTGRES_PASSWORD=postgres \
  --volume=postgres-15-data:/var/lib/postgresql/data \
  --volume=./:/localpath \
  --name=postgres \
  postgres:15.0-alpine3.16
#+end_src

#+begin_src
docker cp  postgres sql_book/Chapter 4: Cohorts/legislators_terms.csv /localpdocker cp  postgres sql_book/Chapter 4: Cohorts/legislators_terms.csv /localpdocker cp  postgres sql_book/Chapter 4: Cohorts/legislators_terms.csv /localpdocker cp  postgres sql_book/Chapter 4: Cohorts/legislators_terms.csv /localpdocker cp  postgres sql_book/Chapter 4: Cohorts/legislators_terms.csv /localpdocker cp  postgres sql_book/Chapter 4: Cohorts/legislators_terms.csv /localpdocker cp  postgres sql_book/Chapter 4: Cohorts/legislators_terms.csv /localpdocker cp  postgres sql_book/Chapter 4: Cohorts/legislators_terms.csv /localpdocker cp  postgres sql_book/Chapter 4: Cohorts/legislators_terms.csv /localpdocker cp  postgres sql_book/Chapter 4: Cohorts/legislators_terms.csv /localpdocker cp  postgres sql_book/Chapter 4: Cohorts/legislators_terms.csv /localpdocker cp  postgres sql_book/Chapter 4: Cohorts/legislators_terms.csv /localpdocker cp  postgres sql_book/Chapter 4: Cohorts/legislators_terms.csv /localpdocker cp  postgres sql_book/Chapter 4: Cohorts/legislators_terms.csv /localpdocker cp  postgres sql_book/Chapter 4: Cohorts/legislators_terms.csv /localpdocker cp  postgres sql_book/Chapter 4: Cohorts/legislators_terms.csv /localpdocker cp  postgres sql_book/Chapter 4: Cohorts/legislators_terms.csv /localpdocker cp  postgres sql_book/Chapter 4: Cohorts/legislators_terms.csv /localpath
#+end_src

起動したコンテナで動作しているPostgreSQLに接続します。ここではdocker execを用いてコンテナ内にあるpsqlコマンドを利用しサーバに接続します。

#+caption: PostgreSQLサーバに接続する
#+begin_src bash
docker exec -it postgres psql -U postgres
#+end_src


* 3. データの投入

各フォルダは章ごとに分かれています。主に =create_= で始まる名前のファイルは、テーブルを作成する際のDDLが記述されています。サンプルデータは、DDLと同じSQLファイルに記載されている場合と、CSV形式で保存されており、DDLのファイルにCOPYコマンドを用いて取り込むようになっている場合があります。また、各章は前の章のテーブルが定義されていることが前提になっている場合があります。つまり6章を実施する場合、それ以前の5章までに使用したデータを要求されることがあります。なお、SQLとデータ分析について概要を説明している1章と全体のまとめの9章では、SQLコードやデータは登場しないので、フォルダもありません。

** 2章

#+begin_src sql
--
DROP TABLE IF EXISTS country_populations;
CREATE TABLE country_populations (
       country text NOT NULL,
       year_1980 integer,
       year_1990 integer,
       year_2000 integer,
       year_2010 integer
);
INSERT INTO country_populations
  (country, year_1980, year_1990, year_2000, year_2010)
VALUES
  ('Canada', 24593, 27791, 31100, NULL),
  ('Mexico', 68347, NULL, NULL, NULL),
  ('United States', 227225, NULL, NULL, NULL)
;
--
DROP TABLE IF EXISTS populations;
CREATE TABLE populations (
  country text,
  population integer
);
INSERT INTO populations (country, population)
VALUES
  ('Canada', 24593),
  ('Mexico', 68347),
  ('United States', 227225);
DROP TABLE IF EXISTS gdp;
CREATE TABLE gdp (
  country text,
  gdp integer
);
INSERT INTO gdp (country, gdp)
VALUES
  ('Canada', 1988336),
  ('Mexico', 1297661),
  ('United States', 22996075);


--
DROP TABLE IF EXISTS customers;
CREATE TABLE customers (
  customer_id integer PRIMARY KEY,
  customer_name text,
  customer_email text,
  gender char(1)
);
INSERT INTO customers (customer_id, customer_name, customer_email, gender)
VALUES
  (1, 'alice', 'alice@example.com', 'F'),
  (2, 'bob'  , 'bob@example.com'  , 'M'),
  (3, 'carol', 'carol@example.com', 'F'),
  (4, 'david', 'david@example.com', 'F');

--
DROP TABLE IF EXISTS transactions;
CREATE TABLE transactions (
  transaction_id integer PRIMARY KEY,
  customer_id integer
);
INSERT INTO transactions (transaction_id, customer_id)
VALUES
  (1, 1),
  (2, 1),
  (3, 2),
  (4, 2),
  (5, 3),
  (6, 3),
  (7, 3);


--
DROP TABLE IF EXISTS orders;
CREATE TABLE orders (
  order_id integer PRIMARY KEY,
  customer_id integer,
  order_amount decimal,
  sales integer,
  transaction_date date,
  order_date date,
  item_id integer,
  product text
);
INSERT INTO orders (
  order_id,
  customer_id,
  order_amount,
  sales,
  transaction_date,
  order_date,
  item_id,
  product
) VALUES
  (1, 123,   59.99,    1000, '2023-05-01', '2023-05-01', 1, 'shirt'),
  (2, 234,   120.55,   1000, '2023-05-02', '2023-05-02', 2, 'shirt'),
  (3, 345,   87.99,    1000, '2023-05-03', '2023-05-03', 1, 'shirt'),
  (90, 999,  5208.57,  1000, '2023-05-01', '2023-05-01', 1, 'shirt'),
  (91, 999,  1211.65,  1000, '2023-05-01', '2023-05-01', 1, 'shoes'),
  (92, 999,  562.250,  1000, '2023-05-01', '2023-05-01', 1, 'hat'),
  (93, 999,  5413.29,  1000, '2023-05-02', '2023-05-02', 1, 'shirt'),
  (94, 999,  522.25,   1000, '2023-05-02', '2023-05-02', 1, 'shoes'),
  (95, 999,  325.62,   1000, '2023-05-02', '2023-05-02', 1, 'hat'),
  (96, 999,  5898.86,  1000, '2023-05-03', '2023-05-03', 1, 'shirt'),
  (97, 999,  1088.62,  1000, '2023-05-03', '2023-05-03', 1, 'shoes'),
  (98, 999,  858.35,   1000, '2023-05-03', '2023-05-03', 1, 'hat');

--
DROP TABLE IF EXISTS nps_responses;
CREATE TABLE nps_responses (
  response_id integer PRIMARY KEY,
  customer_id integer,
  likelihood integer,
  country text,
  high_value boolean
);
INSERT INTO nps_responses (response_id, customer_id, likelihood, country, high_value)
VALUES
  (1, 1, 4 , 'JP', FALSE),
  (2, 1, 5 , 'JP', FALSE),
  (3, 1, 6 , 'CA', FALSE),
  (4, 1, 7 , 'CA', FALSE),
  (5, 2, 8 , 'US', TRUE),
  (6, 2, 9 , 'CA', TRUE),
  (7, 3, 10, 'US', TRUE),
  (8, 3, 0 , 'US', TRUE);

--
DROP TABLE IF EXISTS fruit_orders;
DROP TYPE IF EXISTS fruit_t;
CREATE TYPE fruit_t AS ENUM ('orange', 'apple');
CREATE TABLE fruit_orders (
       customer_id integer,
       fruit fruit_t,
       quantity integer
);
INSERT INTO fruit_orders (customer_id, fruit, quantity)
VALUES
  (1, 'orange', 2),
  (2, 'apple' , 7),
  (3, 'orange', 5),
  (3, 'apple' , 6);


--
DROP TABLE IF EXISTS customer_subscriptions;
CREATE TABLE customer_subscriptions (
  customer_id integer,
  subscription_date date,
  annual_amount integer
);
INSERT INTO customer_subscriptions
  (customer_id, subscription_date, annual_amount)
VALUES
  (1, '2020-01-01', 1000000),
  (1, '2020-02-01', 1000000),
  (1, '2020-03-01', 1000000),
  (1, '2020-04-01', 1000000);

-- sql_bookからコピー
DROP TABLE IF EXISTS date_dim;
CREATE TABLE date_dim
as  SELECT date::date
    ,to_char(date,'yyyymmdd')::int as date_key
    ,date_part('day',date)::int as day_of_month
    ,date_part('doy',date)::int as day_of_year
    ,date_part('dow',date)::int as day_of_week
    ,trim(to_char(date, 'Day')) as day_name
    ,trim(to_char(date, 'Dy')) as day_short_name
    ,date_part('week',date)::int as week_number
    ,to_char(date,'W')::int as week_of_month
    ,date_trunc('week',date)::date as week
    ,date_part('month',date)::int as month_number
    ,trim(to_char(date, 'Month')) as month_name
    ,trim(to_char(date, 'Mon')) as month_short_name
    ,date_trunc('month',date)::date as first_day_of_month
    ,(date_trunc('month',date) + interval '1 month' - interval '1 day')::date as last_day_of_month
    ,date_part('quarter',date)::int as quarter_number
    ,trim('Q' || date_part('quarter',date)::int) as quarter_name
    ,date_trunc('quarter',date)::date as first_day_of_quarter
    ,(date_trunc('quarter',date) + interval '3 months' - interval '1 day')::date as last_day_of_quarter
    ,date_part('year',date)::int as year
    ,date_part('decade',date)::int * 10 as decade
    ,date_part('century',date)::int as centurys
    FROM generate_series('1770-01-01'::date, '2030-12-31'::date, '1 day') as date
    ;
#+end_src

** 3章

#+begin_src sql
DROP TABLE IF EXISTS retail_sales;
CREATE TABLE retail_sales (
       sales_month date,
       sales integer,
       kind_of_business text
);
INSERT INTO retail_sales (sales_month, sales, kind_of_business)
VALUES
  ('1992-01-01', 146376, 'Retail and food services sales, total'),
  ('1992-02-01', 147079, 'Retail and food services sales, total'),
  ('1992-03-01', 159336, 'Retail and food services sales, total'),
  ('1993-01-01', 2153095, 'Retail and food services sales, total'),
  ('1994-01-01', 2330235, 'Retail and food services sales, total'),
  ('1992-01-01', 8327, 'Book stores'),
  ('1992-01-01', 11251, 'Hobby, toy, and game stores'),
  ('1992-01-01', 15583, 'Sporting goods stores'),
  ('1992-01-01', 701, 'Men''s clothing stores'),
  ('1992-01-01', 1873, 'Women''s clothing stores'),
  ('1992-02-01', 1991, 'Women''s clothing stores'),
  ('1993-01-01', 9962, 'Men''s clothing stores'),
  ('1993-01-01', 217, 'Men''s clothing stores'),
  ('1993-01-01', 32350, 'Women''s clothing stores'),
  ('1993-01-01', 32350, 'Women''s clothing stores'),
  ('1994-01-01', 30585, 'Women''s clothing stores'),
  ('1994-01-01', 10032, 'Men''s clothing stores'),
  ('2019-01-01', 2511, 'Women''s clothing stores'),
  ('2019-02-01', 2680, 'Women''s clothing stores'),
  ('2019-03-01', 3585, 'Women''s clothing stores'),
  ('2019-04-01', 3604, 'Women''s clothing stores'),
  ('2019-05-01', 3807, 'Women''s clothing stores'),
  ('2019-06-01', 3272, 'Women''s clothing stores'),
  ('2019-07-01', 3261, 'Women''s clothing stores'),
  ('2019-08-01', 3325, 'Women''s clothing stores'),
  ('2019-09-01', 3080, 'Women''s clothing stores'),
  ('2019-10-01', 3390, 'Women''s clothing stores'),
  ('2019-11-01', 3850, 'Women''s clothing stores'),
  ('2019-12-01', 4496, 'Women''s clothing stores');


DROP TABLE IF EXISTS date_dim;
CREATE TABLE date_dim (
       date date,
       first_day_of_month date
);
INSERT INTO date_dim (date, first_day_of_month)
VALUES
  ('1993-01-01', '1993-01-01'),
  ('1993-02-01', '1993-02-01'),
  ('1993-03-01', '1993-03-01');
#+end_src

** 4章

以下のファイルに記載されているDDLを、SQLで実行することでテーブルを定義します。

- sql_book/Chapter 4: Cohorts/create_legislators_table.sql
- sql_book/Chapter 4: Cohorts/create_legislators_terms.sql

データ投入はCOPYコマンドを用いて次のように実行します。

#+begin_src sql
COPY legislators
  FROM '/workdir/sql_book/Chapter 4: Cohorts/legislators.csv'
  DELIMITER ','
  CSV HEADER;

COPY legislators_terms
  FROM '/workdir/sql_book/Chapter 4: Cohorts/legislators_terms.csv'
  DELIMITER ','
  CSV HEADER;
#+end_src

** 5章

以下のファイルに記載されているDDLを、SQLで実行することでテーブルを定義します。 =create_stop_words.sql= についてはファイル内のINSERT文を実行することでデータを投入します。

- sql_book/Chapter 5: Text Analysis/create_stop_words.sql
- sql_book/Chapter 5: Text Analysis/create_ufo.sql

UFOのデータはCOPYコマンドを用いて次のように投入します。

#+begin_src sql
COPY ufo
  FROM '/workdir/sql_book/Chapter 5: Text Analysis/ufo1.csv'
  DELIMITER ',' CSV HEADER;

COPY ufo
  FROM '/workdir/sql_book/Chapter 5: Text Analysis/ufo2.csv'
  DELIMITER ',' CSV HEADER;

COPY ufo
  FROM '/workdir/sql_book/Chapter 5: Text Analysis/ufo3.csv'
  DELIMITER ',' CSV HEADER;

COPY ufo
  FROM '/workdir/sql_book/Chapter 5: Text Analysis/ufo4.csv'
  DELIMITER ',' CSV HEADER;

COPY ufo
  FROM '/workdir/sql_book/Chapter 5: Text Analysis/ufo5.csv'
  DELIMITER ',' CSV HEADER;
#+end_src

** 6章

以下のファイルに記載されているDDLを、SQLで実行することでテーブルを定義します。

- sql_book/Chapter 6: Anomaly Detection/create_earthquakes_table.sql

データ投入はCOPYコマンドを用いて次のように実行できます。

#+begin_src sql
COPY earthquakes
  FROM '/workdir/sql_book/Chapter 6: Anomaly Detection/earthquakes1.csv'
  DELIMITER ',' CSV HEADER;
     
COPY earthquakes
  FROM '/workdir/sql_book/Chapter 6: Anomaly Detection/earthquakes2.csv'
  DELIMITER ',' CSV HEADER;
     
COPY earthquakes
  FROM '/workdir/sql_book/Chapter 6: Anomaly Detection/earthquakes3.csv'
  DELIMITER ',' CSV HEADER;
     
COPY earthquakes
  FROM '/workdir/sql_book/Chapter 6: Anomaly Detection/earthquakes4.csv'
  DELIMITER ',' CSV HEADER;
     
COPY earthquakes
  FROM '/workdir/sql_book/Chapter 6: Anomaly Detection/earthquakes5.csv'
  DELIMITER ',' CSV HEADER;
     
COPY earthquakes
  FROM '/workdir/sql_book/Chapter 6: Anomaly Detection/earthquakes6.csv'
  DELIMITER ',' CSV HEADER;
     
COPY earthquakes
  FROM '/workdir/sql_book/Chapter 6: Anomaly Detection/earthquakes7.csv'
  DELIMITER ',' CSV HEADER;

COPY earthquakes
  FROM '/workdir/sql_book/Chapter 6: Anomaly Detection/earthquakes8.csv'
  DELIMITER ',' CSV HEADER;

COPY earthquakes
  FROM '/workdir/sql_book/Chapter 6: Anomaly Detection/earthquakes9.csv'
  DELIMITER ',' CSV HEADER;

COPY earthquakes
  FROM '/workdir/sql_book/Chapter 6: Anomaly Detection/earthquakes10.csv'
  DELIMITER ',' CSV HEADER;

COPY earthquakes
  FROM '/workdir/sql_book/Chapter 6: Anomaly Detection/earthquakes11.csv'
  DELIMITER ',' CSV HEADER;

COPY earthquakes
  FROM '/workdir/sql_book/Chapter 6: Anomaly Detection/earthquakes12.csv'
  DELIMITER ',' CSV HEADER;

COPY earthquakes
  FROM '/workdir/sql_book/Chapter 6: Anomaly Detection/earthquakes13.csv'
  DELIMITER ',' CSV HEADER;

COPY earthquakes
  FROM '/workdir/sql_book/Chapter 6: Anomaly Detection/earthquakes14.csv'
  DELIMITER ',' CSV HEADER;

COPY earthquakes
  FROM '/workdir/sql_book/Chapter 6: Anomaly Detection/earthquakes15.csv'
  DELIMITER ',' CSV HEADER;

#+end_src

** 7章

以下のファイルに記載されているDDLを、SQLで実行することでテーブルを定義します。

- sql_book/Chapter 7: Experiment Analysis/create_exp_tables.sql

データ投入はCOPYコマンドを用いて次のように実行します。

#+begin_src sql
COPY game_users
  FROM '/workdir/sql_book/Chapter 7: Experiment Analysis/game_users.csv'
  DELIMITER ',' CSV HEADER;
  
COPY game_actions
  FROM '/workdir/sql_book/Chapter 7: Experiment Analysis/game_actions.csv'
  DELIMITER ',' CSV HEADER;
  
COPY game_purchases
  FROM '/workdir/sql_book/Chapter 7: Experiment Analysis/game_purchases.csv'
  DELIMITER ',' CSV HEADER;

COPY exp_assignment
  FROM '/workdir/sql_book/Chapter 7: Experiment Analysis/exp_assignment.csv'
  DELIMITER ',' CSV HEADER;

#+end_src

** 8章

以下のファイルに記載されているDDLを、SQLで実行することでテーブルを定義します。

- sql_book/Chapter 8: Creating Complex Data Sets/create_videogame_sales.sql

データ投入はCOPYコマンドを用いて次のように実行します。

#+begin_src sql
COPY videogame_sales
  FROM '/workdir/sql_book/Chapter 8: Creating Complex Data Sets/videogame_sales.csv'
  DELIMITER ',' CSV HEADER;

#+end_src

* 正誤表

正誤表は準備中です。誤植や間違いなどを見つけた場合、[[mailto:japan@oreilly.co.jp][japan@oreilly.co.jp]]までお知らせください。
